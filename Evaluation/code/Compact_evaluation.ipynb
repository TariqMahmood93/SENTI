{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bc6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- CONFIG -------------------\n",
    "ROOT = Path(\"/root/workspace/Data/outputs\")\n",
    "RELIN_DIR = ROOT.parent / \"relative_improvement\"\n",
    "FINAL_DIR = ROOT.parent / \"Final_results\"\n",
    "RELIN_DIR.mkdir(exist_ok=True)\n",
    "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATASETS = [\"adultsample\", \"australian\", \"contraceptive\", \"credit\", \"imdb\"]\n",
    "SEEDS = [ 1234]\n",
    "PERCENTAGES = [5, 10, 20, 40]\n",
    "ONE_PERCENTAGE = 10\n",
    "PATTERNS = {\n",
    "    \"sent\":    \"SENT-I_evaluations_{dat}_{seed}.csv\",\n",
    "    \"fixed\":   \"IPM_evaluations_fixed_{dat}_{seed}.csv\",\n",
    "    \"retrain\": \"IPM_evaluations_Retraining_{dat}_{seed}.csv\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977024e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- PART 1: GENERATE RELATIVE IMPROVEMENTS -------------------\n",
    "all_results = []\n",
    "null_col_name = None\n",
    "\n",
    "for dat in DATASETS:\n",
    "    for seed in SEEDS:\n",
    "        # Build file paths\n",
    "        path_sent    = ROOT / PATTERNS[\"sent\"].format(dat=dat, seed=seed)\n",
    "        path_fixed   = ROOT / PATTERNS[\"fixed\"].format(dat=dat, seed=seed)\n",
    "        path_retrain = ROOT / PATTERNS[\"retrain\"].format(dat=dat, seed=seed)\n",
    "\n",
    "        # Check existence\n",
    "        if not (path_sent.exists() and path_fixed.exists() and path_retrain.exists()):\n",
    "            print(f\"[WARN] Missing raw CSV for {dat}, seed {seed}\")\n",
    "            continue\n",
    "\n",
    "        # Load DataFrames\n",
    "        df_sent    = pd.read_csv(path_sent)\n",
    "        df_fixed   = pd.read_csv(path_fixed)\n",
    "        df_retrain = pd.read_csv(path_retrain)\n",
    "\n",
    "        # Detect null-fraction column\n",
    "        cols_sent    = [c for c in df_sent.columns if \"nulls\" in c.lower()]\n",
    "        cols_fixed   = [c for c in df_fixed.columns if \"nulls\" in c.lower()]\n",
    "        cols_retrain = [c for c in df_retrain.columns if \"nulls\" in c.lower()]\n",
    "        if not (cols_sent and cols_fixed and cols_retrain):\n",
    "            print(f\"[ERROR] Null column missing for {dat}, seed {seed}\")\n",
    "            continue\n",
    "        if len({cols_sent[0], cols_fixed[0], cols_retrain[0]}) != 1:\n",
    "            print(f\"[ERROR] Inconsistent null columns for {dat}, seed {seed}\")\n",
    "            continue\n",
    "\n",
    "        null_col = cols_sent[0]\n",
    "        if null_col_name is None:\n",
    "            null_col_name = null_col\n",
    "\n",
    "        # Metric columns\n",
    "        sim_s       = \"avg_semantic_sim_SENTI\"\n",
    "        time_s      = \"total_time_SENTI\"\n",
    "        sim_f       = \"avg_semantic_sim_IPM_fixed\"\n",
    "        time_f      = \"total_time_IPM_fixed\"\n",
    "        imp_time_f  = \"imputation_time_IPM_fixed\"\n",
    "        sim_r       = \"avg_semantic_sim_IPM_70_30_Retraining\"\n",
    "        time_r      = \"total_time_IPM_70_30_Retraining\"\n",
    "\n",
    "        # Select and merge, including imputation time for fixed\n",
    "        df1 = df_sent[[null_col, \"start_index\", \"end_index\", sim_s, time_s]]\n",
    "        df2 = df_fixed[[null_col, \"start_index\", \"end_index\", sim_f, time_f, imp_time_f]]\n",
    "        df3 = df_retrain[[null_col, \"start_index\", \"end_index\", sim_r, time_r]]\n",
    "        df = df1.merge(df2, on=[null_col, \"start_index\", \"end_index\"]) \\\n",
    "               .merge(df3, on=[null_col, \"start_index\", \"end_index\"] )\n",
    "\n",
    "        # Compute effective IPM_fixed time: total_time for first chunk (start_index==0) for all null %, then imputation_time otherwise\n",
    "        df['effective_time_IPM_fixed'] = df.apply(\n",
    "            lambda row: row[time_f] if row['start_index'] == 0 else row[imp_time_f],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Compute improvements\n",
    "        df[\"Over_IPM_fixed\"]     = (df[sim_s] - df[sim_f]) / df[sim_f] * 100\n",
    "        df[\"Over_IPM_retrained\"] = (df[sim_s] - df[sim_r]) / df[sim_r] * 100\n",
    "        df[\"OverTime_IPM_fixed\"]     = (df['effective_time_IPM_fixed'] - df[time_s]) / df['effective_time_IPM_fixed'] * 100\n",
    "        df[\"OverTime_IPM_retrained\"] = (df[time_r] - df[time_s]) / df[time_r] * 100\n",
    "        df[\"FracTime_IPM_fixed\"]     = df['effective_time_IPM_fixed'] / df[time_s]\n",
    "        df[\"FracTime_IPM_retrained\"] = df[time_r] / df[time_s]\n",
    "\n",
    "        # Add context\n",
    "        df.insert(0, \"seed\", seed)\n",
    "        df.insert(0, \"dataset\", dat)\n",
    "\n",
    "        # Save per-seed CSV\n",
    "        out_path = RELIN_DIR / f\"{dat}_{seed}_relative_improvement.csv\"\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f\"[INFO] Saved detailed improvements: {out_path}\")\n",
    "\n",
    "        all_results.append((dat, df))\n",
    "\n",
    "# Concatenate and summary\n",
    "if all_results and null_col_name:\n",
    "    grouped = defaultdict(list)\n",
    "    for dat, df in all_results:\n",
    "        grouped[dat].append(df)\n",
    "\n",
    "    concat_results = {}\n",
    "    for dat, dfs in grouped.items():\n",
    "        df_concat = pd.concat(dfs, ignore_index=True)\n",
    "        concat_path = RELIN_DIR / f\"{dat}_relative_improvement.csv\"\n",
    "        df_concat.to_csv(concat_path, index=False)\n",
    "        print(f\"[INFO] Saved concatenated file for {dat}: {concat_path}\")\n",
    "        concat_results[dat] = df_concat\n",
    "\n",
    "    for dat, df_concat in concat_results.items():\n",
    "        summary = df_concat.groupby([\"dataset\", null_col_name]).agg({\n",
    "            \"Over_IPM_fixed\":           \"mean\",\n",
    "            \"Over_IPM_retrained\":       \"mean\",\n",
    "            \"OverTime_IPM_fixed\":       \"mean\",\n",
    "            \"OverTime_IPM_retrained\":   \"mean\",\n",
    "            \"FracTime_IPM_fixed\":       \"mean\",\n",
    "            \"FracTime_IPM_retrained\":   \"mean\",\n",
    "        }).reset_index().rename(columns={\n",
    "            null_col_name:                \"pct_nulls\",\n",
    "            \"Over_IPM_fixed\":            \"avg_over_sim_IPM_fixed(%)\",\n",
    "            \"Over_IPM_retrained\":        \"avg_over_sim_IPM_retrained(%)\",\n",
    "            \"OverTime_IPM_fixed\":        \"avg_over_time_IPM_fixed(%)\",\n",
    "            \"OverTime_IPM_retrained\":    \"avg_over_time_IPM_retrained(%)\",\n",
    "            \"FracTime_IPM_fixed\":        \"avg_frac_time_IPM_fixed\",\n",
    "            \"FracTime_IPM_retrained\":    \"avg_frac_time_IPM_retrained\",\n",
    "        }).sort_values([\"pct_nulls\"])\n",
    "\n",
    "        summary_path = RELIN_DIR / f\"average_relative_improvement_{dat}.csv\"\n",
    "        summary.to_csv(summary_path, index=False)\n",
    "        print(f\"[INFO] Saved averaged summary for {dat}: {summary_path}\")\n",
    "else:\n",
    "    print(\"[INFO] No data to summarize or null column not detected.\")\n",
    "\n",
    "# -------------------GAIN & TIME RATIOS-------------------\n",
    "global_records = []\n",
    "for dataset in DATASETS:\n",
    "    summary_records = []\n",
    "    for pct in PERCENTAGES:\n",
    "        gains_ipm, gains_fixed = [], []\n",
    "        time_ipm, time_fixed = [], []\n",
    "\n",
    "        for seed in SEEDS:\n",
    "            fp = RELIN_DIR / f\"{dataset}_{seed}_relative_improvement.csv\"\n",
    "            if not fp.exists():\n",
    "                continue\n",
    "            df = pd.read_csv(fp)\n",
    "            # Filter by null percentage\n",
    "            df = df[df[null_col_name] == pct]\n",
    "            if df.shape[0] < 2:\n",
    "                continue\n",
    "            # Ensure chunk size\n",
    "            chunk = df.iloc[1]['end_index'] - df.iloc[1]['start_index']\n",
    "            df = df[df['end_index'] - df['start_index'] >= chunk]\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                senti = df['avg_semantic_sim_SENTI'].values\n",
    "                ipm = df['avg_semantic_sim_IPM_70_30_Retraining'].values\n",
    "                fixed = df['avg_semantic_sim_IPM_fixed'].values\n",
    "                senti_t = df['total_time_SENTI'].values\n",
    "                ipm_t = df['total_time_IPM_70_30_Retraining'].values\n",
    "                fixed_t = df['effective_time_IPM_fixed'].values\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            gains_ipm.extend(((senti - ipm) / ipm) * 100)\n",
    "            gains_fixed.extend(((senti - fixed) / fixed) * 100)\n",
    "            time_ipm.extend(ipm_t / senti_t)\n",
    "            time_fixed.extend(fixed_t / senti_t)\n",
    "\n",
    "        summary_records.append({\n",
    "            \"Dataset\": dataset,\n",
    "            \"Null %\": pct,\n",
    "            \"SENTI over IPM accuracy (%)\": np.mean(gains_ipm),\n",
    "            \"SENTI over IPM_fixed accuracy (%)\": np.mean(gains_fixed),\n",
    "            \"SENTI/IPM time ratio (x)\": np.mean(time_ipm),\n",
    "            \"SENTI/IPM_fixed time ratio (x)\": np.mean(time_fixed),\n",
    "        })\n",
    "        if pct == ONE_PERCENTAGE:\n",
    "            global_records.append(summary_records[-1])\n",
    "\n",
    "    # Compute per-dataset overall\n",
    "    df_sum = pd.DataFrame(summary_records)\n",
    "    summary_records.append({\n",
    "        \"Dataset\": dataset,\n",
    "        \"Null %\": \"Overall\",\n",
    "        \"SENTI over IPM accuracy (%)\": df_sum[\"SENTI over IPM accuracy (%)\"].mean(),\n",
    "        \"SENTI over IPM_fixed accuracy (%)\": df_sum[\"SENTI over IPM_fixed accuracy (%)\"].mean(),\n",
    "        \"SENTI/IPM time ratio (x)\": df_sum[\"SENTI/IPM time ratio (x)\"].mean(),\n",
    "        \"SENTI/IPM_fixed time ratio (x)\": df_sum[\"SENTI/IPM_fixed time ratio (x)\"].mean(),\n",
    "    })\n",
    "\n",
    "    # Save per-dataset final CSV\n",
    "    df_out = pd.DataFrame(summary_records)\n",
    "    out_fp = FINAL_DIR / f\"{dataset}_avg_gains_and_time_ratios.csv\"\n",
    "    df_out.to_csv(out_fp, index=False)\n",
    "    print(f\"Saved: {out_fp}\")\n",
    "\n",
    "# Global summary for ONE_PERCENTAGE\n",
    "global_df = pd.DataFrame(global_records)\n",
    "if not global_df.empty:\n",
    "    global_overall = {\n",
    "        \"Dataset\": \"Overall\",\n",
    "        \"Null %\": ONE_PERCENTAGE,\n",
    "        \"SENTI over IPM accuracy (%)\": global_df[\"SENTI over IPM accuracy (%)\"].mean(),\n",
    "        \"SENTI over IPM_fixed accuracy (%)\": global_df[\"SENTI over IPM_fixed accuracy (%)\"].mean(),\n",
    "        \"SENTI/IPM time ratio (x)\": global_df[\"SENTI/IPM time ratio (x)\"].mean(),\n",
    "        \"SENTI/IPM_fixed time ratio (x)\": global_df[\"SENTI/IPM_fixed time ratio (x)\"].mean(),\n",
    "    }\n",
    "    global_df.loc[len(global_df)] = global_overall\n",
    "    final_global_fp = FINAL_DIR / f\"average_gains_and_time_ratios_{ONE_PERCENTAGE}pct.csv\"\n",
    "    global_df.to_csv(final_global_fp, index=False)\n",
    "    print(f\" Saved: {final_global_fp}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tariq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
